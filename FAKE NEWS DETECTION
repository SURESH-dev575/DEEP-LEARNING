# -------------------------------
# 1. IMPORT LIBRARIES
# -------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# -------------------------------
# 2. LOAD YOUR CSV FILE
# -------------------------------
df = pd.read_csv("/mnt/data/evaluation.csv", 
                 delimiter=';', 
                 engine='python',
                 on_bad_lines='skip')

print("Dataset Loaded!")
print(df.head())
print(df.info())

# -------------------------------
# 3. DROP NULLS
# -------------------------------
df = df.dropna()
print("After removing NaNs:", df.shape)

# -------------------------------
# 4. COMBINE TITLE + TEXT
# -------------------------------
df["content"] = df["title"].astype(str) + " " + df["text"].astype(str)

# -------------------------------
# 5. EXTRACT X AND y
# -------------------------------
X = df["content"]
y = df["label"].astype(int)

# -------------------------------
# 6. TF-IDF VECTORIZATION
# -------------------------------
tfidf = TfidfVectorizer(
    max_features=20000,
    stop_words="english"
)

X = tfidf.fit_transform(X).toarray()
print("TF-IDF shape:", X.shape)

# -------------------------------
# 7. TRAIN-TEST SPLIT
# -------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# -------------------------------
# 8. ANN MODEL (Sequential)
# -------------------------------
model = Sequential([
    Dense(512, activation='relu', input_dim=X_train.shape[1]),
    Dropout(0.4),
    Dense(256, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()

# -------------------------------
# 9. TRAIN THE MODEL
# -------------------------------
history = model.fit(
    X_train, y_train,
    epochs=5,
    validation_split=0.2,
    batch_size=64
)

# -------------------------------
# 10. EVALUATE MODEL
# -------------------------------
loss, acc = model.evaluate(X_test, y_test)
print("Test Accuracy:", acc)

# -------------------------------
# 11. PREDICTION
# -------------------------------
y_pred = (model.predict(X_test) > 0.5).astype(int)

print(classification_report(y_test, y_pred))

# -------------------------------
# 12. CONFUSION MATRIX
# -------------------------------
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# -------------------------------
# 13. CUSTOM PREDICTION FUNCTION
# -------------------------------
def predict_news(title, text):
    sample = title + " " + text
    sample_vec = tfidf.transform([sample]).toarray()
    pred = model.predict(sample_vec)[0][0]

    if pred > 0.5:
        return "REAL NEWS"
    else:
        return "FAKE NEWS"

# -------------------------------
# TEST THE FUNCTION
# -------------------------------
print(predict_news(
    "Government announces new policy",
    "The government today launched a major scheme for health sector..."
))
